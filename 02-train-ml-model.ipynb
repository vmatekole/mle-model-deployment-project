{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Regression Model\n",
    "\n",
    "In this notebook we will train a Linear Regression Model on the Green Taxi Dataset. We will only use one month for the training. And keep only a small number of features. \n",
    "\n",
    "We want the model to predict the duration of a trip. This can be useful for the taxi drivers to plan their trips, for the customers to know how long a trip will take but also for the taxi companies to plan their fleet. The first two predictions would need real time predictions because the duration of a trip is not known in advance. The last one could be done in batch mode, as it is more a analytical task that doesn't need to be done in real time.\n",
    "\n",
    "Additionally, we will use MLFlow to track the model training and log the model artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import mlflow\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.pipeline import Pipeline,make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2021\n",
    "month = 1\n",
    "color = \"green\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2023-07-12 13:30:47--  https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2021-01.parquet\n",
      "Resolving d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)... 18.244.115.167, 18.244.115.220, 18.244.115.202, ...\n",
      "Connecting to d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)|18.244.115.167|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1333519 (1,3M) [binary/octet-stream]\n",
      "Saving to: ‘./data/green_tripdata_2021-01.parquet’\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  3%  504K 2s\n",
      "    50K .......... .......... .......... .......... ..........  7% 3,01M 1s\n",
      "   100K .......... .......... .......... .......... .......... 11% 1,43M 1s\n",
      "   150K .......... .......... .......... .......... .......... 15% 5,38M 1s\n",
      "   200K .......... .......... .......... .......... .......... 19% 3,82M 1s\n",
      "   250K .......... .......... .......... .......... .......... 23% 1,67M 1s\n",
      "   300K .......... .......... .......... .......... .......... 26% 2,71M 1s\n",
      "   350K .......... .......... .......... .......... .......... 30% 1,59M 1s\n",
      "   400K .......... .......... .......... .......... .......... 34% 98,0M 0s\n",
      "   450K .......... .......... .......... .......... .......... 38% 35,4M 0s\n",
      "   500K .......... .......... .......... .......... .......... 42% 3,38M 0s\n",
      "   550K .......... .......... .......... .......... .......... 46% 1,44M 0s\n",
      "   600K .......... .......... .......... .......... .......... 49%  121M 0s\n",
      "   650K .......... .......... .......... .......... .......... 53%  108M 0s\n",
      "   700K .......... .......... .......... .......... .......... 57% 8,43M 0s\n",
      "   750K .......... .......... .......... .......... .......... 61% 10,3M 0s\n",
      "   800K .......... .......... .......... .......... .......... 65% 2,79M 0s\n",
      "   850K .......... .......... .......... .......... .......... 69%  139M 0s\n",
      "   900K .......... .......... .......... .......... .......... 72%  181M 0s\n",
      "   950K .......... .......... .......... .......... .......... 76% 2,42M 0s\n",
      "  1000K .......... .......... .......... .......... .......... 80%  141M 0s\n",
      "  1050K .......... .......... .......... .......... .......... 84%  101M 0s\n",
      "  1100K .......... .......... .......... .......... .......... 88% 5,41M 0s\n",
      "  1150K .......... .......... .......... .......... .......... 92% 31,7M 0s\n",
      "  1200K .......... .......... .......... .......... .......... 95% 10,8M 0s\n",
      "  1250K .......... .......... .......... .......... .......... 99% 29,1M 0s\n",
      "  1300K ..                                                    100% 45,3K=0,4s\n",
      "\n",
      "2023-07-12 13:30:48 (3,47 MB/s) - ‘./data/green_tripdata_2021-01.parquet’ saved [1333519/1333519]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download the data\n",
    "if not os.path.exists(f\"./data/{color}_tripdata_{year}-{month:02d}.parquet\"):\n",
    "    os.system(f\"wget -P ./data https://d37ci6vzurychx.cloudfront.net/trip-data/{color}_tripdata_{year}-{month:02d}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "\n",
    "df = pd.read_parquet(f\"./data/{color}_tripdata_{year}-{month:02d}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76518, 20)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will set up the connection to MLFlow. For that we have to create a `.env` file with the URI to the MLFlow Server in gcp (this will be `http://<external-ip>:5000`). You can simply run:\n",
    "\n",
    "```bash\n",
    "echo \"MLFLOW_TRACKING_URI=http://<external-ip>:5000\" > .env\n",
    "```\n",
    "\n",
    "We also will create an experiment to track the model and the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "MLFLOW_TRACKING_URI=os.getenv(\"MLFLOW_TRACKING_URI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/07/12 13:32:42 INFO mlflow.tracking.fluent: Experiment with name 'green-taxi-trip-duration' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='gs://mlflow-artifacts-vm/mlflow/1', creation_time=1689161562535, experiment_id='1', last_update_time=1689161562535, lifecycle_stage='active', name='green-taxi-trip-duration', tags={}>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up the connection to MLflow\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "\n",
    "# Setup the MLflow experiment \n",
    "mlflow.set_experiment(\"green-taxi-trip-duration\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If everything went well, you should be able to see the experiment now in the MLFlow UI at `http://<external-ip>:5000`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start now with looking at the data a bit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>lpep_pickup_datetime</th>\n",
       "      <th>lpep_dropoff_datetime</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>ehail_fee</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>trip_type</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-01 00:15:56</td>\n",
       "      <td>2021-01-01 00:19:52</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43</td>\n",
       "      <td>151</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.01</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6.80</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-01 00:25:59</td>\n",
       "      <td>2021-01-01 00:34:44</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>166</td>\n",
       "      <td>239</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.53</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>16.86</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-01 00:45:57</td>\n",
       "      <td>2021-01-01 00:51:55</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41</td>\n",
       "      <td>42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.12</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-12-31 23:57:51</td>\n",
       "      <td>2021-01-01 00:04:56</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>168</td>\n",
       "      <td>75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.99</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9.30</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-01 00:16:36</td>\n",
       "      <td>2021-01-01 00:16:40</td>\n",
       "      <td>N</td>\n",
       "      <td>2.0</td>\n",
       "      <td>265</td>\n",
       "      <td>265</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-52.80</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID lpep_pickup_datetime lpep_dropoff_datetime store_and_fwd_flag  \\\n",
       "0         2  2021-01-01 00:15:56   2021-01-01 00:19:52                  N   \n",
       "1         2  2021-01-01 00:25:59   2021-01-01 00:34:44                  N   \n",
       "2         2  2021-01-01 00:45:57   2021-01-01 00:51:55                  N   \n",
       "3         2  2020-12-31 23:57:51   2021-01-01 00:04:56                  N   \n",
       "4         2  2021-01-01 00:16:36   2021-01-01 00:16:40                  N   \n",
       "\n",
       "   RatecodeID  PULocationID  DOLocationID  passenger_count  trip_distance  \\\n",
       "0         1.0            43           151              1.0           1.01   \n",
       "1         1.0           166           239              1.0           2.53   \n",
       "2         1.0            41            42              1.0           1.12   \n",
       "3         1.0           168            75              1.0           1.99   \n",
       "4         2.0           265           265              3.0           0.00   \n",
       "\n",
       "   fare_amount  extra  mta_tax  tip_amount  tolls_amount ehail_fee  \\\n",
       "0          5.5    0.5      0.5        0.00           0.0      None   \n",
       "1         10.0    0.5      0.5        2.81           0.0      None   \n",
       "2          6.0    0.5      0.5        1.00           0.0      None   \n",
       "3          8.0    0.5      0.5        0.00           0.0      None   \n",
       "4        -52.0    0.0     -0.5        0.00           0.0      None   \n",
       "\n",
       "   improvement_surcharge  total_amount  payment_type  trip_type  \\\n",
       "0                    0.3          6.80           2.0        1.0   \n",
       "1                    0.3         16.86           1.0        1.0   \n",
       "2                    0.3          8.30           1.0        1.0   \n",
       "3                    0.3          9.30           2.0        1.0   \n",
       "4                   -0.3        -52.80           3.0        1.0   \n",
       "\n",
       "   congestion_surcharge  \n",
       "0                  0.00  \n",
       "1                  2.75  \n",
       "2                  0.00  \n",
       "3                  0.00  \n",
       "4                  0.00  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 76518 entries, 0 to 76517\n",
      "Data columns (total 20 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   VendorID               76518 non-null  int64         \n",
      " 1   lpep_pickup_datetime   76518 non-null  datetime64[ns]\n",
      " 2   lpep_dropoff_datetime  76518 non-null  datetime64[ns]\n",
      " 3   store_and_fwd_flag     40471 non-null  object        \n",
      " 4   RatecodeID             40471 non-null  float64       \n",
      " 5   PULocationID           76518 non-null  int64         \n",
      " 6   DOLocationID           76518 non-null  int64         \n",
      " 7   passenger_count        40471 non-null  float64       \n",
      " 8   trip_distance          76518 non-null  float64       \n",
      " 9   fare_amount            76518 non-null  float64       \n",
      " 10  extra                  76518 non-null  float64       \n",
      " 11  mta_tax                76518 non-null  float64       \n",
      " 12  tip_amount             76518 non-null  float64       \n",
      " 13  tolls_amount           76518 non-null  float64       \n",
      " 14  ehail_fee              0 non-null      object        \n",
      " 15  improvement_surcharge  76518 non-null  float64       \n",
      " 16  total_amount           76518 non-null  float64       \n",
      " 17  payment_type           40471 non-null  float64       \n",
      " 18  trip_type              40471 non-null  float64       \n",
      " 19  congestion_surcharge   40471 non-null  float64       \n",
      "dtypes: datetime64[ns](2), float64(13), int64(3), object(2)\n",
      "memory usage: 11.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VendorID                     0\n",
       "lpep_pickup_datetime         0\n",
       "lpep_dropoff_datetime        0\n",
       "store_and_fwd_flag       36047\n",
       "RatecodeID               36047\n",
       "PULocationID                 0\n",
       "DOLocationID                 0\n",
       "passenger_count          36047\n",
       "trip_distance                0\n",
       "fare_amount                  0\n",
       "extra                        0\n",
       "mta_tax                      0\n",
       "tip_amount                   0\n",
       "tolls_amount                 0\n",
       "ehail_fee                76518\n",
       "improvement_surcharge        0\n",
       "total_amount                 0\n",
       "payment_type             36047\n",
       "trip_type                36047\n",
       "congestion_surcharge     36047\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nearly all features seem to be in the correct type and we have only missings in features that we will not use for the model training. For predicting the duration of a trip, we will use the following features:\n",
    "\n",
    "- `PULocationID`: The pickup location ID\n",
    "- `DOLocationID`: The dropoff location ID\n",
    "- `trip_distance`: The distance of the trip in miles\n",
    "\n",
    "But first we have to calculate the duration of the trip in minutes because it is our target. For that we will use the `tpep_pickup_datetime` and `tpep_dropoff_datetime` columns. We will also remove all trips that have a duration of 0 and that are longer than 1 hours to remove outliers.\n",
    "\n",
    "Additionally we will transform `DOLocationID` and `PULocationID` to categorical features. And combine them to a new feature `trip_route` that will contain the route of the trip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"PULocationID\", \"DOLocationID\", \"trip_distance\"]\n",
    "target = 'duration'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the trip duration in minutes and drop trips that are less than 1 minute and more than 2 hours\n",
    "def calculate_trip_duration_in_minutes(df):\n",
    "    df[\"trip_duration_minutes\"] = (df[\"lpep_dropoff_datetime\"] - df[\"lpep_pickup_datetime\"]).dt.total_seconds() / 60\n",
    "    df = df[(df[\"trip_duration_minutes\"] >= 1) & (df[\"trip_duration_minutes\"] <= 60)]\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    df = df.copy()\n",
    "    df = calculate_trip_duration_in_minutes(df)\n",
    "    categorical_features = [\"PULocationID\", \"DOLocationID\"]\n",
    "    df[categorical_features] = df[categorical_features].astype(str)\n",
    "    df['trip_route'] = df[\"PULocationID\"] + \"_\" + df[\"DOLocationID\"]\n",
    "    df = df[['trip_route', 'trip_distance', 'trip_duration_minutes']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed = preprocess(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the dataframe that we want to train our model on. We need to split it into a train and test set. We will use 80% of the data for training and 20% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df_processed[\"trip_duration_minutes\"]\n",
    "X=df_processed.drop(columns=[\"trip_duration_minutes\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now combine the `trip_distance` and the `trip_route` in a dictionary and transform it with the [DictVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.DictVectorizer.html) from `sklearn` to a sparse matrix, which is basically a one hot encoding of the categorical features and includes the distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv = DictVectorizer()\n",
    "\n",
    "dv.fit(X_train.to_dict(orient=\"records\"))\n",
    "X_train = dv.transform(X_train.to_dict(orient=\"records\"))\n",
    "X_test = dv.transform(X_test.to_dict(orient=\"records\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can train the model and track the experiment with MLFlow. We will set tags to the experiment to make it easier to find it later.\n",
    "\n",
    "- `model`: `linear-regression`\n",
    "- `dataset`: `yellow-taxi`\n",
    "- `developer`: `your-name`\n",
    "- `train_size`: The size of the train set\n",
    "- `test_size`: The size of the test set\n",
    "- `features`: The features that we used for training\n",
    "- `target`: The target that we want to predict\n",
    "- `year`: The year of the data\n",
    "- `month`: The month of the data\n",
    "\n",
    "We could also log the model parameters but Linear Regression doesn't have any.\n",
    "\n",
    "And finally we will log the metrics:\n",
    "\n",
    "- `rmse`: The root mean squared error\n",
    "\n",
    "We will also log the model artifacts. For that we will need to set the `service account json` that we downloaded earlier as the environment variable `GOOGLE_APPLICATION_CREDENTIALS`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "SA_KEY=\"./project-etl.json\"\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = SA_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "    \n",
    "    tags = {\n",
    "        \"model\": \"linear regression\",\n",
    "        \"developer\": \"Victor Matekole\",\n",
    "        \"dataset\": f\"{color}-taxi\",\n",
    "        \"year\": year,\n",
    "        \"month\": month,\n",
    "        \"features\": features,\n",
    "        \"target\": target\n",
    "    }\n",
    "    mlflow.set_tags(tags)\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = lr.predict(X_test)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    \n",
    "    mlflow.sklearn.log_model(lr, \"model\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now see your run in the MLFlow UI. Under the created experiment. You can also see the logged tags, the metric and the saved model.\n",
    "\n",
    "![mlflow-ui](./images/mlflow-run.png)\n",
    "\n",
    "And you can see what you need to do to load the model in an API or script in the UI as long as the application has access to MLFlow."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But now let's add the `DictVectorizer` and the model to a pipeline and run the training again. First we need to create a new pair of train and test set because we will do the transformation in the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.to_dict(orient=\"records\")\n",
    "X_test = X_test.to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "    \n",
    "    tags = {\n",
    "        \"model\": \"linear regression pipeline\",\n",
    "        \"developer\": \"<your name>\",\n",
    "        \"dataset\": f\"{color}-taxi\",\n",
    "        \"year\": year,\n",
    "        \"month\": month,\n",
    "        \"features\": features,\n",
    "        \"target\": target\n",
    "    }\n",
    "    mlflow.set_tags(tags)\n",
    "    pipeline = make_pipeline(\n",
    "         DictVectorizer(),\n",
    "        LinearRegression()\n",
    "    )\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    \n",
    "    mlflow.sklearn.log_model(pipeline, \"model\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you should see a new experiment with a new run id in MLFlow. You can also see the pipeline and the model in the UI under `Artifacts`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
